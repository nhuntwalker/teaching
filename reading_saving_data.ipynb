{
 "metadata": {
  "name": ""
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "heading",
     "level": 1,
     "metadata": {},
     "source": [
      "Reading and Saving Data with Python"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Author: Nicholas Hunt-Walker\n",
      "\n",
      "Date of Origin: 6/3/2014\n",
      "\n",
      "Class: Astro 480\n",
      "\n",
      "This is a brief tutorial of how to read in data you can work with, and output data you want to save.  This is of course not an exhaustive walkthrough. It'll just show you some options you can use. Namely, the ones that I use on a regular basis."
     ]
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Import Package"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "<b>Numpy</b> will allow us to read data, make arrays, and use those arrays, making visualizing and manipulating data simple. We use the alias of \"np\" instead of the full name because it's easier than typing out \"numpy\" every time we want to use a function or module from numpy. We also use \"np\" instead of just importing all of numpy's functions and modules because we want to be able to differentiate between numpy's components and Python's pre-packaged components."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import numpy as np"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 1
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Reading Data"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "There's two functions from numpy that I use for reading in data. The good thing about both of these functions as that all data gets read into numpy arrays (or array-like structures). \n",
      "\n",
      "The first is <b>np.loadtxt</b>, which is good for reading in data that's all of the same format (so all strings or all floats).\n",
      "\n",
      "The second is <b>np.genfromtxt</b>, which is good for reading in data with different formats, and even data with missing entries.\n",
      "\n",
      "The third function that I use for reading in data is the basic python function <b>open( fname ).readlines( )</b>.  It reads every line of your input file into a large list, regardless of format.  Every entry going into that list is a row from your input file."
     ]
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "numpy.loadtxt"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Let's start with a very simple two-column file where every entry is a number. And the columns are separated by white space. I don't feel like making a comma-delimited file right now, so tough luck on that one."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "infile = 'mygalaxy.dat'\n",
      "mydata = np.loadtxt( infile )"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 3
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "This reads every line from the file into \"mydata\" as a row.  Observe the first 5 rows of \"mydata\"..."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print mydata[:5]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "[[ 49.3317     3.74013 ]\n",
        " [ 50.3509     4.76035 ]\n",
        " [ 65.766      1.99268 ]\n",
        " [ 46.5797     4.27444 ]\n",
        " [ 25.0454     0.277328]]\n"
       ]
      }
     ],
     "prompt_number": 4
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "If I already know how my data is supposed to look, I can instead choose to read in the columns separately by setting the key word \"unpack = True\"."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "column_1, column_2 = np.loadtxt( infile, unpack=True)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 5
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print column_1[:5]\n",
      "print column_2[:5]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "[ 49.3317  50.3509  65.766   46.5797  25.0454]\n",
        "[ 3.74013   4.76035   1.99268   4.27444   0.277328]\n"
       ]
      }
     ],
     "prompt_number": 7
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Now I'm ready to work with that data and do whatever I need with it. How I can work with it is outside the scope of this particular document, but yeah. There it is."
     ]
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "numpy.genfromtxt"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Let's say our data is a little more complex. Instead of just two columns (which in this case were galactic longitude and latitude), we have 30 columns, with mixed formats. We have some that are integers (that we want to keep as integers), some with floats, and some with strings.  If you try to use np.loadtxt to read this file (in its entirety), it'll throw an error at you.  This is where <b>np.genfromtxt</b> comes to save the day!"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "infile = 'known_agbs_selected.dat'\n",
      "mydata = np.genfromtxt(infile)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 35
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "As a heads up, this data's 30 columns are of the format \"int, float, float, float, ... , float, string\", where the \"...\" means I'm too lazy to write \"float\" 24 more times. I say this to say that while np.genfromtxt will read in your data regardless of its format, it'll try to turn *everything* into a float. If you happen to have a string in your data it'll throw you a \"nan\", or \"not a number\".  Observe."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print mydata[0]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "[  2.00000000e+00   2.87066000e+02   1.62893000e+01   4.93317000e+01\n",
        "   3.74013000e+00   3.91600000e+00   3.46600000e+00   2.77700000e+00\n",
        "   1.81900000e+00   3.35000000e-01   1.89000000e-01   1.40000000e-02\n",
        "   1.70000000e-02   3.20000000e+00   5.70000000e+00   7.96000000e+01\n",
        "   6.46000000e+01   5.63600000e+00   4.64700000e+00   4.00900000e+00\n",
        "   1.80000000e-02   3.60000000e-02   3.60000000e-02   4.55718000e-01\n",
        "   1.62700000e+00   1.23200000e+00   4.50000000e-01   6.89000000e-01\n",
        "   9.58000000e-01              nan]\n"
       ]
      }
     ],
     "prompt_number": 36
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Luckily, you can specify the format of each column with the keyword \"dtype\" which, as you can imagine, lets you specify the data type."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "fmt = \"int, float, float, float, float, float, float, float, float, float, float, float, float, float, float, float, float, float, float, float, float, float, float, float, float, float, float, float, float, str\"\n",
      "mydata = np.genfromtxt(infile, dtype=fmt)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 37
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print mydata[1]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "(4, 286.601, 17.6587, 50.3509, 4.76035, 5.912, 4.379, 2.771, 1.393, 0.087, 0.094, 0.011, 0.014, 12.4, 11.5, 100.0, 80.0, 8.138, 6.749, 5.891, 0.023, 0.018, 0.016, 0.281503, 2.247, 3.12, 1.533, 1.608, 1.378, '')\n"
       ]
      }
     ],
     "prompt_number": 38
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "\"I see the integer I wanted in front, but the string that I wanted at the end returned nothing! NOTHING!\" Cool your jets, sonny. The issue here is that you have to actually declare the maximum size of your strings. What that means is, if your largest string is 8 characters long, then you have to say so in your format.  For example, \"starforming\" has 11 characters. If that string was in my last column, I'd have to accommodate that length with \"S8\".\n",
      "\n",
      "In the case of my infile, the max string length is 5 characters long. I like to err on the side of caution though, so I'll use \"S6\"."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "fmt = \"int, float, float, float, float, float, float, float, float, float, float, float, float, float, float, float, float, float, float, float, float, float, float, float, float, float, float, float, float, S6\"\n",
      "mydata = np.genfromtxt(infile, dtype=fmt)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 39
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print mydata[0]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "(2, 287.066, 16.2893, 49.3317, 3.74013, 3.916, 3.466, 2.777, 1.819, 0.335, 0.189, 0.014, 0.017, 3.2, 5.7, 79.6, 64.6, 5.636, 4.647, 4.009, 0.018, 0.036, 0.036, 0.455718, 1.627, 1.232, 0.45, 0.689, 0.958, 'OH/IR')\n"
       ]
      }
     ],
     "prompt_number": 40
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Beautiful! Now, if we actually want to work with this data, having every entry in a gigantic row like this might not be ideal. It depends on what you intend to do with the data.  However, if you're like me, you like to have each column of your data in its own separate variable.  Unlike <b>np.loadtxt</b>, I can't do this just by setting \"unpack=True\". If the data was homogenous I could, but it's not so damn."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "fmt = \"int, float, float, float, float, float, float, float, float, float, float, float, float, float, float, float, float, float, float, float, float, float, float, float, float, float, float, float, float, S6\"\n",
      "mydata = np.genfromtxt(infile, dtype=fmt)\n",
      "\n",
      "n = len(mydata)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 41
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "This is going to look a little cumbersome, but bear with me. I'm going to declare 30 empty variables and fill each one with the appropriate column of data using a \"for\" loop. To ease my work, I'm going to use the size of the data set to inform the size of each variable.\n",
      "\n",
      "Because I know what this data represents, I'm going to give my column variables descriptive names (and not column_1 through column_30). As often as you can, you should use descriptive variables. You never know when you might come back to old, uncommented code and forget what everything means!\n",
      "\n",
      "All my \"empty\" variables start out as np.zeros( ) of length \"n\". For special columns that have data types that aren't floats, I need to set my \"dtype\" equal to what I'm reading in."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "catalog_id = np.zeros(n, dtype=int)\n",
      "ra = np.zeros(n)\n",
      "decl = np.zeros(n)\n",
      "gal_long = np.zeros(n)\n",
      "gal_lat = np.zeros(n)\n",
      "w1mag = np.zeros(n)\n",
      "w2mag = np.zeros(n)\n",
      "w3mag = np.zeros(n)\n",
      "w4mag = np.zeros(n)\n",
      "w1err = np.zeros(n)\n",
      "w2err = np.zeros(n)\n",
      "w3err = np.zeros(n)\n",
      "w4err = np.zeros(n)\n",
      "w1snr = np.zeros(n)\n",
      "w2snr = np.zeros(n)\n",
      "w3snr = np.zeros(n)\n",
      "w4snr = np.zeros(n)\n",
      "jmag = np.zeros(n)\n",
      "hmag = np.zeros(n)\n",
      "kmag = np.zeros(n)\n",
      "jerr = np.zeros(n)\n",
      "herr = np.zeros(n)\n",
      "kerr = np.zeros(n)\n",
      "matching_radius = np.zeros(n)\n",
      "color_jk = np.zeros(n)\n",
      "color_k3 = np.zeros(n)\n",
      "color_12 = np.zeros(n)\n",
      "color_23 = np.zeros(n)\n",
      "color_34 = np.zeros(n)\n",
      "star_type = np.zeros(n, dtype=\"S8\")"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 42
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "And now we start the \"for\" loop. I want my loop to look at every line that I've read into \"mydata\". For a given line (hence the \"<b>for</b>\" part of \"for loop\"), I want to allocate each particular value to its appropriate variable, and loop this procedure over the entire data set (hence the \"<b>loop</b>\" part of \"for loop\")."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "for i in range(n):\n",
      "    line = mydata[i]\n",
      "\n",
      "    catalog_id[i] = line[0]\n",
      "    ra[i] = line[1]\n",
      "    decl[i] = line[2]\n",
      "    gall[i] = line[3]\n",
      "    galb[i] = line[4]\n",
      "    w1mag[i] = line[5]\n",
      "    w2mag[i] = line[6]\n",
      "    w3mag[i] = line[7]\n",
      "    w4mag[i] = line[8]\n",
      "    w1err[i] = line[9]\n",
      "    w2err[i] = line[10]\n",
      "    w3err[i] = line[11]\n",
      "    w4err[i] = line[12]\n",
      "    w1snr[i] = line[13]\n",
      "    w2snr[i] = line[14]\n",
      "    w3snr[i] = line[15]\n",
      "    w4snr[i] = line[16]\n",
      "    jmag[i] = line[17]\n",
      "    hmag[i] = line[18]\n",
      "    kmag[i] = line[19]\n",
      "    jerr[i] = line[20]\n",
      "    herr[i] = line[21]\n",
      "    kerr[i] = line[22]\n",
      "    matching_radius[i] = line[23]\n",
      "    color_jk[i] = line[24]\n",
      "    color_k3[i] = line[25]\n",
      "    color_12[i] = line[26]\n",
      "    color_23[i] = line[27]\n",
      "    color_34[i] = line[28]\n",
      "    star_type[i] = line[29]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 43
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "And now all my data is allocated appropriately.  Look!  Look at all my various star types, with their lovely strings preserved!"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print set(star_type)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "set(['AGB*', 'OH/IR', 'Mira', 'S*', 'C*'])\n"
       ]
      }
     ],
     "prompt_number": 44
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "open( ).readlines( )"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Data isn't always perfect. Sometimes you produce a data file with some errors. Maybe your magnitude-calculation algorithm put out some \"INDEF\"s when it encountered an error. Or your large database has some missing values and records a  \"NAN\" when it hits that value.  <b>np.genfromtxt</b>  can handle those, but I've never used it so bleh.\n",
      "\n",
      "When I encounter such data, I read in the raw file as a list of strings, then replace those \"INDEF\"s or \"NAN\"s with a value that can be turned into a number (like 0, 9999, or -9999).  Let's start that process."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "infile = 'imperfect_data.dat'\n",
      "mydata = open(infile).readlines()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 45
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Let's look at this data"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "for data in mydata:\n",
      "    print data"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "287.066,16.2893,INDEF,3.74013\n",
        "\n",
        "286.601,INDEF,17.6587,4.76035\n",
        "\n",
        "297.294,29.8758,65.766,INDEF\n",
        "\n",
        "INDEF,14.0871,46.5797,4.27444\n",
        "\n",
        "278.997,-6.88683,INDEF,0.277328\n",
        "\n"
       ]
      }
     ],
     "prompt_number": 50
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Look at all those INDEFs! Ugh. I don't want to deal with those.  What I'll do is replace every INDEF with -9999. I use -9999 because it's a clear indicator that something's not kosher.\n",
      "\n",
      "I'll do this by taking every string and using <b>.replace( )</b>. And because you <b>NEVER EVER EVER EVER ALTER YOUR SOURCE DATA</b>, I'm going to start with an empty list and populate the list with the fixed values."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "cleaned_data = []\n",
      "\n",
      "for data_string in mydata:\n",
      "    cleaned_data.append(data_string.replace('INDEF','-9999'))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 52
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "And now we gaze upon our handiwork."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "for data in cleaned_data:\n",
      "    print data"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "287.066,16.2893,-9999,3.74013\n",
        "\n",
        "286.601,-9999,17.6587,4.76035\n",
        "\n",
        "297.294,29.8758,65.766,-9999\n",
        "\n",
        "-9999,14.0871,46.5797,4.27444\n",
        "\n",
        "278.997,-6.88683,-9999,0.277328\n",
        "\n"
       ]
      }
     ],
     "prompt_number": 53
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Beautiful!\n",
      "\n",
      "Now we have the job of allocating this data to the appropriate variables.  This is more or less random data, but I'm going to use descriptive variables anyway because it's a good habit to be in.\n",
      "\n",
      "As with before, we start with arrays of zeros."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "n = len(cleaned_data)\n",
      "\n",
      "gross_domestic_product = np.zeros(n)\n",
      "population_millions = np.zeros(n)\n",
      "tax_revenue = np.zeros(n)\n",
      "exports = np.zeros(n)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 54
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "This won't be quite the same as with np.genfromtxt, because each line is a large string.  The first thing to do is split each line into its constituent parts using <b>.split( )</b>. The <b>.split( )</b> module, if left empty, will automatically split up a string into individual components based on white space (like spaces and tabs).  With our data, we want to specify that our data is comma-delimited.  As such, we use <b>.split(',')</b>. Splitting a string in this way goes as follows:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "example_string = cleaned_data[0].split(',')\n",
      "print example_string"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "['287.066', '16.2893', '-9999', '3.74013\\n']\n"
       ]
      }
     ],
     "prompt_number": 55
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Don't worry about that '\\n' at the end. That's just a bit of text telling the file to start a new line after that value. When we evaluate it, it'll go away automatically. As far as evaluating these strings goes, we can use either the <b>eval( )</b> function, or <b>float( )</b>."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print float(example_string[0])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "287.066\n"
       ]
      }
     ],
     "prompt_number": 57
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print eval(example_string[3])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "3.74013\n"
       ]
      }
     ],
     "prompt_number": 58
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Now that we know what we'll be doing with each value in each line, let's allocate like we did with <b>np.genfromtxt</b>."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "for jj in range(len(cleaned_data)):\n",
      "    data_line = cleaned_data[jj].split(',')\n",
      "    \n",
      "    gross_domestic_product[jj] = eval(data_line[0])\n",
      "    population_millions[jj] = eval(data_line[1])\n",
      "    tax_revenue[jj] = eval(data_line[2])\n",
      "    exports[jj] = eval(data_line[3])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 59
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "And now look at our data!"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print gross_domestic_product"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "[  287.066   286.601   297.294 -9999.      278.997]\n"
       ]
      }
     ],
     "prompt_number": 60
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "As you gain more skill in programming with python, you'll write a function to do this for you so that you don't have to type all this crap out. But for now, gaze upon our wonderous works."
     ]
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Saving Data"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "So you've read in your data, you've done your science to it, and now you want to save it to a file so that you can show your professor or advisor how brilliant you are. How do we do this? There's at least 3 ways that I know of, so I'll cover those here.\n",
      "\n",
      "- <b>fout = open( 'file_name', 'w'); fout.write('some stuff')</b>\n",
      "- <b>np.savetxt</b>\n",
      "- <b>pickle.dump( data, open( 'file_name', 'w') )</b>"
     ]
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "Basic Output with Python"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "That first option is my data writing workhorse. In fact, I can say with all certainty that I barely even glanced at np.savetxt before writing this tutorial, and I only use pickle.dump on rare occasions (like saving a dictionary, DataFrame, or some other object). The way it works is simple. First, you open a file that you want to write to. The 'w' means \"write\".\n",
      "\n",
      "<b>REALLY REALLY IMPORTANT NOTE: IF YOU OPEN AN ALREADY-EXISTING FILE, SIMPLY OPENING THAT FILE IN THIS PARTICULAR WAY WILL ERASE IT, EVEN IF YOU DON'T WRITE ANYTHING!! ANY TIME YOU DO THIS, YOU ARE ESSENTIALLY CREATING A BRAND NEW DOCUMENT!! BE VERY AWARE!!</b>"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "output_filename = 'myoutput.dat'\n",
      "fout = open(output_filename, 'w')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 61
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Ok, now I've opened my file for writing. It's now ready and waiting for data. Just to kill two birds with one stone, let's save my mixed-format data from earlier (the one with the different star types).  To do this, we'll work with the basic principle that what I'm writing out to \"myoutput.dat\" is a series of lines, where each line is one long string.  With that in mind I can format each entry into that string, based of course on the data type that I'm putting in each entry. I avoid using \"format\" as a variable because that's actually the name of something in Python. It's a good idea to not try to replace pre-existing variable names.\n",
      "\n",
      "Just as a personal note, I would never separate my \"file opening\" part from my \"data writing\" part like this. It's usually all in one cell. But hell, I'm writing a tutorial, so these things happen."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "fmt = \"%i %g %g %s\\n\""
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 62
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "So what did I just write? This string will be my template for every line that I output to file. So what's being written here? An integer, a number whose entire format I'm preserving as is, another number with preserved format, and then a string of some length (length need not be specified in my experience). I'm separating each entry with one space, and I'm telling my text file to start a new line after it's done writing my data. \n",
      "\n",
      "<b>Note:</b> This doesn't only apply to writing data to file! You can print your data to screen like this too.  Check it:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print fmt % (catalog_id[0], ra[0], decl[0], star_type[0])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "2 287.066 16.2893 OH/IR\n",
        "\n"
       ]
      }
     ],
     "prompt_number": 64
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "See that? It kept the spacing, kept the data formats, and didn't output the \"\\n\" or the % symbols.\n",
      "\n",
      "We can separate our data however we want! Some systems use tabs \"\\t\", some use commas \",\", and some use pipes \"|\". Whatever you use, remember that anything you write in the format string that's not preceded by \"\\\" or \"%\" <b>will be written</b>.\n",
      "\n",
      "Let's write to our file now. For every entry in each column, we write each data value one at a time.  This sounds like another <b>loop</b>!"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "for kk in range(len(catalog_id)):\n",
      "    fout.write( fmt % (catalog_id[kk], ra[kk], decl[kk], star_type[kk]))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 65
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Make sure you close your file when you're done writing to it."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "fout.close()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 66
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Thus, the whole thing together looks like this..."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "output_filename = 'myoutput.dat'\n",
      "fout = open(output_filename, 'w')\n",
      "fmt = \"%i %g %g %s\\n\"\n",
      "for kk in range(len(catalog_id)):\n",
      "    fout.write( fmt % (catalog_id[kk], ra[kk], decl[kk], star_type[kk]))\n",
      "fout.close()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 67
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "np.savetxt"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Like I said before, I never even looked at this until today, so my explanation will be undoubtedly lackluster. You can use this to save arrays easily. You can also save multiple arrays, but they have to all have to have the same format.\n",
      "\n",
      "Something of an issue with this, aside from requiring all arrays to be of the same format, is that the output isn't in columns for each array, but in rows for each array. Meaning, your output will be a row of all the values in array 1, then the next row is all of array 2, etc. This only applies when saving multiple arrays. Singular arrays are maintained as a column.\n",
      "\n",
      "Still, if you want to use this, here's a brief example."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "some_numbers = np.arange(10)\n",
      "more_numbers = np.arange(10,20)\n",
      "lots_numbers = np.arange(20.0,30.0)\n",
      "\n",
      "output_filename = 'savetxt_output.dat'\n",
      "np.savetxt(output_filename, some_numbers) ## saves as a column\n",
      "np.savetxt(output_filename, (some_numbers, more_numbers, lots_numbers), fmt=\"%f\") ## saves as rows, and also can only have one format"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 79
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "pickle"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "I like <b>pickle</b>, not least because of the silly name. As the name implies, pickling an object preserves it for the future. It's really nice and efficient, though from what I can tell you can only pickle one \"thing\" at a time.\n",
      "\n",
      "I typically use pickle when saving a dictionary, or a DataFrame when using Pandas. First, let's initialize it."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import pickle"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 80
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "I love a simple first step, don't you?\n",
      "\n",
      "Pickle is actually very straightforward. You have an object that you want to save. You tell pickle to open a file (usually with a .p file type) and pickle that <b>one</b> object using that file. And that's it! You're done!  Let's do this now. \n",
      "\n",
      "Start by populating a dictionary with information. Note that every entry in a dictionary need not be the same length, nor do they even need to be the same data format. You can put anything you want into a dictionary, even another dictionary!"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "lovely_dictionary = {'Right Ascension': ra, 'Declination': decl, 'Star Type': star_type}"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 83
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Alright, so I've declared my lovely dictionary. Now because it's so lovely, I want to preserve it forever! Let's pickle this badboy using <b>pickle.dump</b>"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "pickle.dump(lovely_dictionary, open('lovely_dictionary.p','w'))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 84
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "That's really all there is to it. Your dictionary is now saved. You can check by unpickling that object, using <b>pickle.load( )</b>"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "checking_stuff = pickle.load(open('lovely_dictionary.p'))\n",
      "print checking_stuff"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "{'Right Ascension': array([ 287.066 ,  286.601 ,  297.294 , ...,   20.2337,   20.2721,\n",
        "         20.8087]), 'Star Type': array(['OH/IR', 'OH/IR', 'OH/IR', ..., 'C*', 'C*', 'C*'], \n",
        "      dtype='|S8'), 'Declination': array([ 16.2893,  17.6587,  29.8758, ..., -71.3862, -73.1857, -71.9107])}\n"
       ]
      }
     ],
     "prompt_number": 87
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Note that while it does not preserve the original dictionary name, it does preserve the dictionary's keys (which can easily be used as headers), as well as the data types accessed by those keys.\n",
      "\n",
      "This is essentially the thing to use when you want to output complex data structures. It doesn't ask you to provide text formats for anything, or for delimiters or anything of that sort. It just saves the total object as is, ready for you to call it back at some later time. You can also save things like arrays, lists, and tuples, but you can only save those one at a time with pickle. As such, I wouldn't recommend pickle for those data structures.\n",
      "\n",
      "And that's it! I hope you've enjoyed this tutorial!\n",
      "\n",
      "--Nick"
     ]
    }
   ],
   "metadata": {}
  }
 ]
}